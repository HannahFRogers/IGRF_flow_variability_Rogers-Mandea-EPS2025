{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "783fef19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path\n",
    "import tornado\n",
    "import scipy\n",
    "import h5py\n",
    "import sys\n",
    "import numpy as np\n",
    "from numpy.matlib import repmat\n",
    "import pandas as pd\n",
    "import pylab\n",
    "import matplotlib.path as mpath\n",
    "import random\n",
    "import chaosmagpy as cp\n",
    "import statsmodels.api as sm\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import AutoMinorLocator, MultipleLocator\n",
    "from statistics import variance\n",
    "from matplotlib.lines import Line2D\n",
    "import webgeodyn\n",
    "import webgeodyn.server\n",
    "from webgeodyn.models import Models, Model\n",
    "from webgeodyn.filters import time\n",
    "from webgeodyn.filters.spectral import keep_m\n",
    "from webgeodyn.processing import spectra\n",
    "from webgeodyn.inout import s1fs2, midpath, ced, covobs_x2\n",
    "from webgeodyn.constants import rE, rC\n",
    "from webgeodyn.processing import psd #, psd_dev\n",
    "from cartopy import crs as ccrs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c401fe",
   "metadata": {},
   "source": [
    "First we need to prepare the coefficients from the IGRF github to be entered into pygeodyn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d7156a",
   "metadata": {},
   "source": [
    "Function to take the coefficient folders from github.com/IAGA-VMOD/IGRF14eval/tree/main/data/coefficients to put into the 1-year format needed for pygeodyn. Note you will have to change the 'pygeodyn_folder' to be the file of your choice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b5a1152",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygeodyn_folder='PATH'\n",
    "\n",
    "def IGRF_hdf5(group):\n",
    "        \n",
    "    file = str(group)+'.hdf5'\n",
    "    path = str(pygeodyn_folder)+'data/observations/IGRF_14_eval/'+str(group)\n",
    "\n",
    "    try:\n",
    "        os.mkdir(path)\n",
    "    except OSError as error:\n",
    "        print(error)\n",
    "        #os.remove(path+'/'+file)\n",
    "    \n",
    "    if group=='Huber':\n",
    "        DGRF_group = 'Median'\n",
    "    else:\n",
    "        DGRF_group = group\n",
    "    OTHER_group = group\n",
    "    \n",
    "    start_yr=2020\n",
    "    end_yr=2030\n",
    "    step=1\n",
    "    \n",
    "    l_b=13\n",
    "    g=np.array(np.loadtxt('Original/DGRF/DGRF_'+str(DGRF_group)+'.cof')[:,2])\n",
    "    h=np.array(np.loadtxt('Original/DGRF/DGRF_'+str(DGRF_group)+'.cof')[:,3])\n",
    "    gnm_step=[]\n",
    "    var_gnm=[]\n",
    "    k=0\n",
    "    for l in range(1,l_b+1,1):\n",
    "        for m in range(0,l+1,1):\n",
    "            if m==0:\n",
    "                gnm_step.append(g[k])\n",
    "                var_gnm.append(0.001)\n",
    "            else:\n",
    "                gnm_step.append(g[k])\n",
    "                var_gnm.append(0.001)\n",
    "                gnm_step.append(h[k])\n",
    "                var_gnm.append(0.001)\n",
    "            k=k+1\n",
    "    \n",
    "    g_dot=(np.array(np.loadtxt('Original/IGRF/IGRF_'+str(OTHER_group)+'.cof')[:,2])-np.array(np.loadtxt('Original/DGRF/DGRF_'+str(DGRF_group)+'.cof')[:,2]))/(2025.0-2020.0)\n",
    "    h_dot=(np.array(np.loadtxt('Original/IGRF/IGRF_'+str(OTHER_group)+'.cof')[:,3])-np.array(np.loadtxt('Original/DGRF/DGRF_'+str(DGRF_group)+'.cof')[:,3]))/(2025.0-2020.0)\n",
    "    \n",
    "    g=np.array(np.loadtxt('Original/IGRF/IGRF_'+str(OTHER_group)+'.cof')[:,2])\n",
    "    h=np.array(np.loadtxt('Original/IGRF/IGRF_'+str(OTHER_group)+'.cof')[:,3])\n",
    "    \n",
    "    original_IGRF = []\n",
    "    dgnm_step=[]\n",
    "    var_dgnm=[]\n",
    "    k=0\n",
    "    for l in range(1,l_b+1,1):\n",
    "        for m in range(0,l+1,1):\n",
    "            if m==0:\n",
    "                dgnm_step.append(g_dot[k])\n",
    "                var_dgnm.append(0.001)\n",
    "                original_IGRF.append(g[k])\n",
    "            else:\n",
    "                dgnm_step.append(g_dot[k])\n",
    "                var_dgnm.append(0.001)\n",
    "                original_IGRF.append(g[k])\n",
    "                dgnm_step.append(h_dot[k])\n",
    "                var_dgnm.append(0.001)\n",
    "                original_IGRF.append(h[k])\n",
    "            k=k+1\n",
    "                \n",
    "    l_sv=8\n",
    "    g_dot=np.array(np.loadtxt('Original/SV/SV_'+str(OTHER_group)+'.cof')[:,2])\n",
    "    h_dot=np.array(np.loadtxt('Original/SV/SV_'+str(OTHER_group)+'.cof')[:,3])\n",
    "    dgnm_step_25=[]\n",
    "    var_dgnm_step_25=[]\n",
    "    k=0\n",
    "    for l in range(1,l_sv+1,1):\n",
    "        for m in range(0,l+1,1):\n",
    "            if m==0:\n",
    "                dgnm_step_25.append(g_dot[k])\n",
    "                var_dgnm_step_25.append(0.001)\n",
    "            else:\n",
    "                dgnm_step_25.append(g_dot[k])\n",
    "                var_dgnm_step_25.append(0.001)\n",
    "                dgnm_step_25.append(h_dot[k])\n",
    "                var_dgnm_step_25.append(0.001)\n",
    "            k=k+1\n",
    "    for l in range(l_sv+1, l_b+1,1):\n",
    "        for m in range(0,l+1,1):\n",
    "            if m==0:\n",
    "                dgnm_step_25.append(0.0)\n",
    "                var_dgnm_step_25.append(100.0)\n",
    "            else:\n",
    "                dgnm_step_25.append(0.0)\n",
    "                dgnm_step_25.append(0.0)\n",
    "                var_dgnm_step_25.append(100.0)\n",
    "                var_dgnm_step_25.append(100.0)\n",
    "\n",
    "    times_array = []\n",
    "    gnm_array=[]\n",
    "    dgnm_array = []\n",
    "    var_gnm_array=[]\n",
    "    var_dgnm_array=[]\n",
    "    \n",
    "    for times in range(start_yr, end_yr+1, step):\n",
    "        times_array.append(float(times))\n",
    "        \n",
    "        gnm_array.append(np.array(gnm_step))\n",
    "        var_gnm_array.append(np.array(var_gnm))\n",
    "        \n",
    "        if times == 2025.0:\n",
    "            dgnm_step= np.copy(dgnm_step_25)\n",
    "            var_dgnm_step = np.copy(var_dgnm_step_25)\n",
    "            # Check IGRF -gnm_step =~ 0\n",
    "            diff = original_IGRF-gnm_step\n",
    "            if np.any(diff>0.0000000005):\n",
    "                print('WARNING DGRF+SV DOES NOT EQUAL IGRF')\n",
    "            \n",
    "        dgnm_array.append(np.array(dgnm_step))\n",
    "        var_dgnm_array.append(np.array(var_dgnm))\n",
    "        \n",
    "        gnm_step = np.array(gnm_step)+np.array(dgnm_step)\n",
    "    \n",
    "    gnm_realisations = np.zeros((200, 11, 195))\n",
    "    dgnm_realisations = np.zeros((200, 11, 195))\n",
    "    gnm_realisations[:] = gnm_array\n",
    "    dgnm_realisations[:] = dgnm_array\n",
    "    \n",
    "    with h5py.File(path+'/'+file, 'w') as f:\n",
    "        f.create_dataset('dgnm', data=dgnm_realisations)\n",
    "        f.create_dataset('gnm', data=gnm_realisations)\n",
    "        f.create_dataset('times', data=times_array)\n",
    "        f.create_dataset('var_gnm', data=var_gnm_array)\n",
    "        f.create_dataset('var_dgnm', data=var_dgnm_array)\n",
    "        \n",
    "    print('Saved file: ' + str(file))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1930e08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list=['BGS','CSES','GFZ','Huber','IPGP','ISTERRE','MISTA','NOAA','Strasbourg','TU_Berlin','UCM','USTHB','WHU']\n",
    "for j in range(len(group_list)):\n",
    "    IGRF_hdf5(group_list[j])    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f826d5c4",
   "metadata": {},
   "source": [
    "After downloading the model from https://www.spacecenter.dk/files/magnetic-models/CHAOS-8/ you can then run this to produce the DTU model with a higher SV degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3204870d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CHAOS model at Lsv=13\n",
    "file = 'DTU_13.hdf5'\n",
    "start_yr=2020\n",
    "end_yr=2030\n",
    "step=1\n",
    "path = str(pygeodyn_folder)+'data/observations/IGRF_14_eval/DTU13'\n",
    "\n",
    "l_b=13\n",
    "g=np.array(np.loadtxt('Original/DGRF/DGRF_'+str('DTU')+'.cof')[:,2])\n",
    "h=np.array(np.loadtxt('Original/DGRF/DGRF_'+str('DTU')+'.cof')[:,3])\n",
    "gnm_step=[]\n",
    "var_gnm=[]\n",
    "k=0\n",
    "for l in range(1,l_b+1,1):\n",
    "    for m in range(0,l+1,1):\n",
    "        if m==0:\n",
    "            gnm_step.append(g[k])\n",
    "            var_gnm.append(0.001)\n",
    "        else:\n",
    "            gnm_step.append(g[k])\n",
    "            var_gnm.append(0.001)\n",
    "            gnm_step.append(h[k])\n",
    "            var_gnm.append(0.001)\n",
    "        k=k+1\n",
    "\n",
    "g_dot=(np.array(np.loadtxt('Original/IGRF/IGRF_'+str('DTU')+'.cof')[:,2])-np.array(np.loadtxt('Original/DGRF/DGRF_'+str('DTU')+'.cof')[:,2]))/(2025.0-2020.0)\n",
    "h_dot=(np.array(np.loadtxt('Original/IGRF/IGRF_'+str('DTU')+'.cof')[:,3])-np.array(np.loadtxt('Original/DGRF/DGRF_'+str('DTU')+'.cof')[:,3]))/(2025.0-2020.0)\n",
    "\n",
    "g=np.array(np.loadtxt('Original/IGRF/IGRF_'+str('DTU')+'.cof')[:,2])\n",
    "h=np.array(np.loadtxt('Original/IGRF/IGRF_'+str('DTU')+'.cof')[:,3])\n",
    "\n",
    "original_IGRF = []\n",
    "dgnm_step=[]\n",
    "var_dgnm=[]\n",
    "k=0\n",
    "for l in range(1,l_b+1,1):\n",
    "    for m in range(0,l+1,1):\n",
    "        if m==0:\n",
    "            dgnm_step.append(g_dot[k])\n",
    "            var_dgnm.append(0.001)\n",
    "            original_IGRF.append(g[k])\n",
    "        else:\n",
    "            dgnm_step.append(g_dot[k])\n",
    "            var_dgnm.append(0.001)\n",
    "            original_IGRF.append(g[k])\n",
    "            dgnm_step.append(h_dot[k])\n",
    "            var_dgnm.append(0.001)\n",
    "            original_IGRF.append(h[k])\n",
    "        k=k+1\n",
    "\n",
    "l_sv=13\n",
    "model = cp.load_CHAOS_matfile(str(pygeodyn_folder)+'data/observations/CHAOS-8/CHAOS-8-1.mat')\n",
    "time = 2025.0\n",
    "dgnm_step_25 = model.synth_coeffs_tdep(time, nmax=13, deriv=1)  # shape: (10, 224)\n",
    "var_dgnm_step_25=[]\n",
    "k=0\n",
    "for l in range(1,l_sv+1,1):\n",
    "    for m in range(0,l+1,1):\n",
    "        if m==0:\n",
    "            var_dgnm_step_25.append(0.001)\n",
    "        else:\n",
    "            var_dgnm_step_25.append(0.001)\n",
    "            var_dgnm_step_25.append(0.001)\n",
    "        k=k+1\n",
    "\n",
    "times_array = []\n",
    "gnm_array=[]\n",
    "dgnm_array = []\n",
    "var_gnm_array=[]\n",
    "var_dgnm_array=[]\n",
    "\n",
    "for times in range(start_yr, end_yr+1, step):\n",
    "    times_array.append(float(times))\n",
    "\n",
    "    gnm_array.append(np.array(gnm_step))\n",
    "    var_gnm_array.append(np.array(var_gnm))\n",
    "\n",
    "    if times == 2025.0:\n",
    "        dgnm_step= np.copy(dgnm_step_25)\n",
    "        var_dgnm_step = np.copy(var_dgnm_step_25)\n",
    "        # Check IGRF -gnm_step =~ 0\n",
    "        diff = original_IGRF-gnm_step\n",
    "        if np.any(diff>0.0000000005):\n",
    "            print('WARNING DGRF+SV DOES NOT EQUAL IGRF')\n",
    "\n",
    "    dgnm_array.append(np.array(dgnm_step))\n",
    "    var_dgnm_array.append(np.array(var_dgnm))\n",
    "\n",
    "    gnm_step = np.array(gnm_step)+np.array(dgnm_step)\n",
    "    \n",
    "gnm_realisations = np.zeros((200, 11, 195))\n",
    "dgnm_realisations = np.zeros((200, 11, 195))\n",
    "gnm_realisations[:] = gnm_array\n",
    "dgnm_realisations[:] = dgnm_array\n",
    "\n",
    "with h5py.File(path+'/'+file, 'w') as f:\n",
    "    f.create_dataset('dgnm', data=dgnm_realisations)\n",
    "    f.create_dataset('gnm', data=gnm_realisations)\n",
    "    f.create_dataset('times', data=times_array)\n",
    "    f.create_dataset('var_gnm', data=var_gnm_array)\n",
    "    f.create_dataset('var_dgnm', data=var_dgnm_array)\n",
    "\n",
    "print('Saved file: ' + str(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a3b545",
   "metadata": {},
   "source": [
    "After downloading the SV model from https://ionocovar.agnld.uni-potsdam.de/Kalmag/Kalmag/Model/ you can then run this to produce the TU_Berlin model with a higher SV degree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3656e349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Kalmag model at Lsv=13\n",
    "path = str(pygeodyn_folder)+'data/observations/IGRF_14_eval/TU_Berlin_13'\n",
    "\n",
    "file = 'TU_Berlin_13.hdf5'\n",
    "start_yr=2020\n",
    "end_yr=2030\n",
    "step=1\n",
    "\n",
    "l_b=13\n",
    "g=np.array(np.loadtxt('Original/DGRF/DGRF_'+str('TU_Berlin')+'.cof')[:,2])\n",
    "h=np.array(np.loadtxt('Original/DGRF/DGRF_'+str('TU_Berlin')+'.cof')[:,3])\n",
    "gnm_step=[]\n",
    "var_gnm=[]\n",
    "k=0\n",
    "for l in range(1,l_b+1,1):\n",
    "    for m in range(0,l+1,1):\n",
    "        if m==0:\n",
    "            gnm_step.append(g[k])\n",
    "            var_gnm.append(0.001)\n",
    "        else:\n",
    "            gnm_step.append(g[k])\n",
    "            var_gnm.append(0.001)\n",
    "            gnm_step.append(h[k])\n",
    "            var_gnm.append(0.001)\n",
    "        k=k+1\n",
    "\n",
    "g_dot=(np.array(np.loadtxt('Original/IGRF/IGRF_'+str('TU_Berlin')+'.cof')[:,2])-np.array(np.loadtxt('Original/DGRF/DGRF_'+str('TU_Berlin')+'.cof')[:,2]))/(2025.0-2020.0)\n",
    "h_dot=(np.array(np.loadtxt('Original/IGRF/IGRF_'+str('TU_Berlin')+'.cof')[:,3])-np.array(np.loadtxt('Original/DGRF/DGRF_'+str('TU_Berlin')+'.cof')[:,3]))/(2025.0-2020.0)\n",
    "\n",
    "g=np.array(np.loadtxt('Original/IGRF/IGRF_'+str('TU_Berlin')+'.cof')[:,2])\n",
    "h=np.array(np.loadtxt('Original/IGRF/IGRF_'+str('TU_Berlin')+'.cof')[:,3])\n",
    "\n",
    "original_IGRF = []\n",
    "dgnm_step=[]\n",
    "var_dgnm=[]\n",
    "k=0\n",
    "for l in range(1,l_b+1,1):\n",
    "    for m in range(0,l+1,1):\n",
    "        if m==0:\n",
    "            dgnm_step.append(g_dot[k])\n",
    "            var_dgnm.append(0.001)\n",
    "            original_IGRF.append(g[k])\n",
    "        else:\n",
    "            dgnm_step.append(g_dot[k])\n",
    "            var_dgnm.append(0.001)\n",
    "            original_IGRF.append(g[k])\n",
    "            dgnm_step.append(h_dot[k])\n",
    "            var_dgnm.append(0.001)\n",
    "            original_IGRF.append(h[k])\n",
    "        k=k+1\n",
    "\n",
    "l_sv=13\n",
    "dgnm_step_25 = np.loadtxt(str(pygeodyn_folder)+'data/observations/IGRF_14_eval/TU_Berlin_13/SV_original.txt')[1:,1]\n",
    "var_dgnm_step_25=[]\n",
    "k=0\n",
    "for l in range(1,l_sv+1,1):\n",
    "    for m in range(0,l+1,1):\n",
    "        if m==0:\n",
    "            var_dgnm_step_25.append(0.001)\n",
    "        else:\n",
    "            var_dgnm_step_25.append(0.001)\n",
    "            var_dgnm_step_25.append(0.001)\n",
    "        k=k+1\n",
    "\n",
    "times_array = []\n",
    "gnm_array=[]\n",
    "dgnm_array = []\n",
    "var_gnm_array=[]\n",
    "var_dgnm_array=[]\n",
    "\n",
    "for times in range(start_yr, end_yr+1, step):\n",
    "    times_array.append(float(times))\n",
    "\n",
    "    gnm_array.append(np.array(gnm_step))\n",
    "    var_gnm_array.append(np.array(var_gnm))\n",
    "\n",
    "    if times == 2025.0:\n",
    "        dgnm_step= np.copy(dgnm_step_25)\n",
    "        var_dgnm_step = np.copy(var_dgnm_step_25)\n",
    "        # Check IGRF -gnm_step =~ 0\n",
    "        diff = original_IGRF-gnm_step\n",
    "        if np.any(diff>0.0000000005):\n",
    "            print('WARNING DGRF+SV DOES NOT EQUAL IGRF')\n",
    "\n",
    "    dgnm_array.append(np.array(dgnm_step))\n",
    "    var_dgnm_array.append(np.array(var_dgnm))\n",
    "\n",
    "    gnm_step = np.array(gnm_step)+np.array(dgnm_step)\n",
    "    \n",
    "gnm_realisations = np.zeros((200, 11, 195))\n",
    "dgnm_realisations = np.zeros((200, 11, 195))\n",
    "gnm_realisations[:] = gnm_array\n",
    "dgnm_realisations[:] = dgnm_array\n",
    "\n",
    "with h5py.File(path+'/'+file, 'w') as f:\n",
    "    f.create_dataset('dgnm', data=dgnm_realisations)\n",
    "    f.create_dataset('gnm', data=gnm_realisations)\n",
    "    f.create_dataset('times', data=times_array)\n",
    "    f.create_dataset('var_gnm', data=var_gnm_array)\n",
    "    f.create_dataset('var_dgnm', data=var_dgnm_array)\n",
    "\n",
    "print('Saved file: ' + str(file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "895242a2",
   "metadata": {},
   "source": [
    "Optional check for the format for pygeodyn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1396c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(str(pygeodyn_folder)+'data/observations/IGRF_14_eval/BGS/BGS.hdf5', 'r') as f:\n",
    "    print(list(f))\n",
    "    print(np.array(f['times'].shape))\n",
    "    print(np.array(f['dgnm'].shape))\n",
    "    print(np.array(f['gnm'].shape))\n",
    "    print(np.array(f['var_gnm'].shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473bc35f",
   "metadata": {},
   "source": [
    "Now the coefficients are in the correct format, we can run the models in pygeodyn. Instructions to run the pygeodyn core flow inversion is here: https://geodynamo.gricad-pages.univ-grenoble-alpes.fr/pygeodyn/index.html\n",
    "\n",
    "An example of a .conf file for the set up given in the paper is here (you will need to add the model name):"
   ]
  },
  {
   "cell_type": "raw",
   "id": "45377717",
   "metadata": {},
   "source": [
    "# The parameters are stored following the format :\n",
    "# param_name type value\n",
    "\n",
    "# NECESSARY PARAMETERS\n",
    "# For the core_state\n",
    "# Max SH degree for the core flow coefficients\n",
    "Lu int 15\n",
    "# Max SH degree for the magnetic field coefficients\n",
    "Lb int 13\n",
    "# Max SH degree for the secular variation and subgrid-errors coefficients\n",
    "Lsv int 13\n",
    "\n",
    "# Starting analysis date\n",
    "t_start_analysis float 2020\n",
    "# Finish analysis data\n",
    "t_end_analysis float 2030\n",
    "# Timestep of forecasts (1 month)\n",
    "dt_f float 0.08333333333333333333333333\n",
    "# dt_a / dt_f ratio (analysis every 12 forecasts = 1 year)\n",
    "dt_a_f_ratio int 12\n",
    "\n",
    "# OPTIONAL PARAMETERS\n",
    "# Number of angles for Legendre polynomials evaluation\n",
    "Nth_legendre int 64\n",
    "# Directory where to find the prior data (relative to the config path)\n",
    "prior_dir str data/priors/71path\n",
    "# Type of the prior data ('0path', '50path', '71path' and '100path')\n",
    "prior_type str 71path\n",
    "\n",
    "# Directory where to find the observation data (relative to the config path)\n",
    "obs_dir str data/observations/IGRF_14_eval/MODEL\n",
    "# Type of observation to consider ('COVOBS', 'COVOBS_hdf5', 'chaos_hdf5', 'KALMAG_hdf5 and 'GO_VO' are supported)\n",
    "obs_type str igrfcompare\n",
    "\n",
    "# Type of the AR process ('diag' (AR1), (dense) 'AR1', (dense) 'AR3')\n",
    "AR_type str diag\n",
    "# Number of coefficients for the PCA of U\n",
    "# If 0 or negative, no PCA will be done (default)\n",
    "N_pca_u int 0\n",
    "# Normalisation to use for U on which the PCA is performed ('energy' or 'None' (default))\n",
    "#pca_norm str energy\n",
    "# Type of initial for the core_state ('normal' or 'from_file')\n",
    "core_state_init str normal\n",
    "\n",
    "# parameters that control the output hdf5 file\n",
    "# Controls whether to output (1) or not (0) the analysis state\n",
    "out_analysis int 1\n",
    "# Controls whether to output (1) or not (0) the forecast state\n",
    "out_forecast int 1\n",
    "# Controls whether to output (1) or not (0) the computed state\n",
    "out_computed int 1\n",
    "# Controls whether to output (1) or not (0) the misfit state\n",
    "out_misfits int 1\n",
    "\n",
    "# reduce noise coming from empirical covariance computation\n",
    "# advised value is 35/Nb_realisations for AR1 \n",
    "remove_spurious float 0.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c303066b",
   "metadata": {},
   "source": [
    "You must also add igrfcompare as a new file type. You will need to change the MODEL every new run. See https://geodynamo.gricad-pages.univ-grenoble-alpes.fr/pygeodyn/usage_new_types.html"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9269ce3",
   "metadata": {},
   "source": [
    "def build_igrfcompare_observations(cfg, nb_realisations, measure_type, seed=None):\n",
    "    \"\"\"\n",
    "    Builds the observations from a hdf5 COVOBS file.\n",
    "    The dates where no analysis takes place are discarded.\n",
    "\n",
    "    :param cfg: configuration of the computation\n",
    "    :type cfg: inout.config.ComputationConfig\n",
    "    :param nb_realisations: Number of realisations of the computation\n",
    "    :type nb_realisations: int\n",
    "    :param measure_type: Type of the measure to extract ('MF' or 'SV')\n",
    "    :type measure_type: str\n",
    "    :return: dictionary of Observation objects with dates (np.datetime64) as keys.\n",
    "    :rtype: dict[np.datetime64, Observation]\n",
    "    \"\"\"\n",
    "    datadir = cfg.obs_dir\n",
    "    if measure_type == 'SV':\n",
    "        max_degree = cfg.Lsv\n",
    "        nb_coefs = cfg.Nsv\n",
    "        dataset_name = 'dgnm'\n",
    "    else:\n",
    "        max_degree = cfg.Lb\n",
    "        nb_coefs = cfg.Nb\n",
    "        dataset_name = 'gnm'\n",
    "\n",
    "    # Find the hdf5 files (sort to have reproducible order of realisations_files)\n",
    "    hdf5_files = sorted(glob.glob(os.path.join(datadir, 'MODEL')))\n",
    "\n",
    "    if len(hdf5_files) == 0:\n",
    "        raise IOError(\"No hdf5 files were found in {} ! Check that it is the valid directory path.\".format(datadir))\n",
    "\n",
    "    logging.debug('Observations are read from {}'.format(hdf5_files[0]))\n",
    "\n",
    "    with h5py.File(hdf5_files[0], 'r') as f:\n",
    "        dates = f['times'][:]\n",
    "        real_data = f[format(dataset_name)][:]\n",
    "        variance_data = f['var_{}'.format(dataset_name)][:]\n",
    "\n",
    "    nb_reals_data, nb_dates_data, nb_coefs_data = real_data.shape\n",
    "    # N = L(L+2) => L = sqrt(N+1) - 1\n",
    "    max_degree_data = np.sqrt(nb_coefs_data + 1) - 1\n",
    "\n",
    "    # Format the data as a dict of Observations with dates as keys\n",
    "    observations = {}\n",
    "    for i_d, date in enumerate(dates):\n",
    "        # Shift the date by one month (different convention)\n",
    "        match_idx = find_obs_analysis_match(date, cfg.t_analyses_full, cfg.dt_f)\n",
    "        if match_idx is None:\n",
    "            continue\n",
    "        # Get asked nb_realisations and nb_coefs\n",
    "        obs_data = real_data[:nb_realisations, i_d, :nb_coefs]\n",
    "        # Get the number of observed coefficients (here equal to nb_coefs)\n",
    "        current_No = obs_data.shape[-1]\n",
    "        # H is identity (spectral data)\n",
    "        H = np.eye(current_No, nb_coefs)\n",
    "        # R is a diagonal matrix with variances as diagonal\n",
    "        R = np.diagflat(variance_data[i_d, :current_No])\n",
    "        observations[match_idx] = Observation(obs_data, H, R)\n",
    "\n",
    "    return observations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42fdea90",
   "metadata": {},
   "source": [
    "Repeat the pygeodyn core flow inversion for all candidate models of your choosing. Alternatively you can access the inversion outputs presented in the paper from the zenodo repository where this notebook is found. Below we introduce the plotting and analysis functions used within the paper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a91ece",
   "metadata": {},
   "source": [
    "Here we define some functions we will use later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473c1e86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the SV or ER spectra calculation\n",
    "def computeSVSpectra(lmax, array2D):\n",
    "    fac_l = np.zeros((lmax))\n",
    "    Spec_tmp = np.zeros(lmax)\n",
    "\n",
    "    k=0\n",
    "    for j in range(lmax):\n",
    "        l=j+1\n",
    "        fac_l[j] = l+1\n",
    "\n",
    "        tmp=0.\n",
    "        for m in range (2*l+1):\n",
    "            tmp = tmp + fac_l[j]*array2D[k]**2\n",
    "            k=k+1\n",
    "        Spec_tmp[j] = tmp\n",
    "\n",
    "    return Spec_tmp\n",
    "\n",
    "## Load models\n",
    "PlotModels = {}\n",
    "LODmodel ={}\n",
    "\n",
    "def readmodelhdf5(file, model_name, col, mark, linesty):\n",
    "    with h5py.File(file) as f:\n",
    "        f_data = f['analysed']\n",
    "        T = np.array(f_data['times'])\n",
    "        U =  np.array(f['analysed']['U'])\n",
    "        SV =  np.array(f['analysed']['SV'])\n",
    "        MF =  np.array(f['analysed']['MF'])\n",
    "        ER =  np.array(f['analysed']['ER'])\n",
    "    Uav = np.mean(U,axis=0)\n",
    "    SVav = np.mean(SV,axis=0)\n",
    "    MFav = np.mean(MF,axis=0)\n",
    "    ERav = np.mean(ER,axis=0)\n",
    "    \n",
    "    Ustd = np.std(U, axis=0)\n",
    "    \n",
    "    PlotModels[model_name] = dict([('Time', T), ('U', Uav), ('Utot', U), ('Ustd', Ustd), ('SV', SVav), ('MF', MFav), ('ER', ERav), ('Color', col), ('Marker', mark), ('LineStyle', linesty)])\n",
    "    return PlotModels\n",
    "\n",
    "\n",
    "# Define the flow and flow diff spectra \n",
    "def computeUSpectra(lmax, array2D):\n",
    "    fac_l = np.zeros((lmax))\n",
    "    Spec_tmp = np.zeros(lmax)\n",
    "\n",
    "    k=0\n",
    "    for j in range(lmax):\n",
    "        l=j+1\n",
    "        fac_l[j] = l*(l+1)/(2*l+1)\n",
    "\n",
    "        tmp=0.\n",
    "        for m in range (2*l+1):\n",
    "            tmp = tmp + fac_l[j]*(array2D[k]**2 + array2D[k+(lmax*(lmax+2))]**2)\n",
    "            k=k+1\n",
    "        Spec_tmp[j] = tmp\n",
    "\n",
    "    return Spec_tmp\n",
    "\n",
    "def correlationcoeff2D(a, b, Nph, Nth):\n",
    "    '''\n",
    "    Assume a and b are 2 maps of the same size where we want to calculate the average correlation coefficient\n",
    "    '''\n",
    "\n",
    "    corr_map = np.zeros((Nth-1, 1))\n",
    "    \n",
    "    for i in range(0,Nth-1):\n",
    "        tmp = np.corrcoef(a[i], b[i])[0,1]\n",
    "        corr_map[i] = tmp\n",
    "    \n",
    "    corrcoeff = np.mean(corr_map,axis=0)\n",
    "    return corrcoeff\n",
    "\n",
    "def readPlotmodelhdf5(file):\n",
    "    with h5py.File(file) as f:\n",
    "        f_data = f['analysed']\n",
    "        T = np.array(f_data['times'])\n",
    "        U =  np.array(f['analysed']['U'])\n",
    "        SV =  np.array(f['analysed']['SV'])\n",
    "        MF =  np.array(f['analysed']['MF'])\n",
    "        ER =  np.array(f['analysed']['ER'])\n",
    "\n",
    "    Uav = np.mean(U,axis=0)\n",
    "    Ustd = np.std(U,axis=0)\n",
    "\n",
    "    SVav = np.mean(SV,axis=0)\n",
    "    ERav = np.mean(ER,axis=0)\n",
    "    MFav = np.mean(MF,axis=0)\n",
    "    \n",
    "    f_model = webgeodyn.models.Model()\n",
    "    f_model.addMeasure(measureName='U',measureType='U',lmax=15,units='km/yr',data=Uav,rmsdata=None,times=T)\n",
    "    f_model.addMeasure(measureName='Ustd',measureType='U',lmax=15,units='km/yr',data=Ustd,rmsdata=None,times=T)\n",
    "    f_model.addMeasure(measureName='MF',measureType='MF',lmax=13,units='nT/yr',data=MFav,rmsdata=None,times=T)\n",
    "    f_model.addMeasure(measureName='SV',measureType='SV',lmax=13,units='nT/yr',data=SVav,rmsdata=None,times=T)\n",
    "    f_model.addMeasure(measureName='ER',measureType='SV',lmax=13,units='nT/yr',data=ERav,rmsdata=None,times=T)\n",
    "    return f_model\n",
    "\n",
    "def compute_huber_weighted_mean(maps, huber_tuning=1.345, verbose=True):\n",
    "    \"\"\"\n",
    "    Computes Huber-weighted mean and weights across models for each pixel.\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    maps : np.ndarray\n",
    "        Input array of shape (num_models, height, width), where each [i, :, :] is a 2D map.\n",
    "    huber_tuning : float\n",
    "        Tuning constant for Huber's loss function (default 1.345).\n",
    "    verbose : bool\n",
    "        Whether to display a progress bar.\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    huber_mean_map : np.ndarray\n",
    "        Robust mean per pixel, shape (height, width).\n",
    "    huber_weights : np.ndarray\n",
    "        Huber weights per model and pixel, shape (num_models, height, width).\n",
    "    \"\"\"\n",
    "    num_models, H, W = maps.shape\n",
    "    huber_mean_map = np.zeros((H, W))\n",
    "    huber_weights = np.zeros((num_models, H, W))\n",
    "\n",
    "    iterator = tqdm(range(H), desc=\"Computing Huber stats\") if verbose else range(H)\n",
    "\n",
    "    for i in iterator:\n",
    "        for j in range(W):\n",
    "            y = maps[:, i, j]\n",
    "\n",
    "            # Skip if all values are nan\n",
    "            if np.all(np.isnan(y)):\n",
    "                huber_mean_map[i, j] = np.nan\n",
    "                huber_weights[:, i, j] = np.nan\n",
    "                continue\n",
    "\n",
    "            # Remove nan entries\n",
    "            valid_idx = ~np.isnan(y)\n",
    "            y_valid = y[valid_idx]\n",
    "            X = np.ones((len(y_valid), 1))  # intercept-only model\n",
    "\n",
    "            try:\n",
    "                rlm_model = sm.RLM(y_valid, X, M=sm.robust.norms.HuberT(t=huber_tuning))\n",
    "                rlm_results = rlm_model.fit()\n",
    "\n",
    "                huber_mean_map[i, j] = rlm_results.params[0]\n",
    "\n",
    "                # Store weights only for valid indices\n",
    "                weights = rlm_results.weights\n",
    "                full_weights = np.zeros(num_models)\n",
    "                full_weights[valid_idx] = weights\n",
    "                huber_weights[:, i, j] = full_weights\n",
    "\n",
    "            except Exception as e:\n",
    "                # Fallback to mean if fitting fails\n",
    "                huber_mean_map[i, j] = np.nanmean(y)\n",
    "                huber_weights[:, i, j] = np.where(valid_idx, 1.0, 0.0)\n",
    "\n",
    "    return huber_mean_map, huber_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b75f60eb",
   "metadata": {},
   "source": [
    "You can either load models individually like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edf0635",
   "metadata": {},
   "outputs": [],
   "source": [
    "pygeodyn_results = 'PATH'\n",
    "with h5py.File(str(pygeodyn_results)+'Huber_Current_computation.hdf5') as f:\n",
    "    f_data = f['analysed']\n",
    "    T = np.array(f_data['times'])\n",
    "    U =  np.array(f['analysed']['U'])\n",
    "    SV =  np.array(f['analysed']['SV'])\n",
    "    MF =  np.array(f['analysed']['MF'])\n",
    "    ER =  np.array(f['analysed']['ER'])\n",
    "\n",
    "Uav = np.mean(U,axis=0)\n",
    "Ustd = np.std(U,axis=0)\n",
    "\n",
    "SVav = np.mean(SV,axis=0)\n",
    "ERav = np.mean(ER,axis=0)\n",
    "MFav = np.mean(MF,axis=0)\n",
    "\n",
    "f_model = webgeodyn.models.Model()\n",
    "f_model.addMeasure(measureName='U',measureType='U',lmax=15,units='km/yr',data=Uav,rmsdata=None,times=T)\n",
    "f_model.addMeasure(measureName='Ustd',measureType='U',lmax=15,units='km/yr',data=Ustd,rmsdata=None,times=T)\n",
    "f_model.addMeasure(measureName='MF',measureType='MF',lmax=13,units='nT/yr',data=MFav,rmsdata=None,times=T)\n",
    "f_model.addMeasure(measureName='SV',measureType='SV',lmax=13,units='nT/yr',data=SVav,rmsdata=None,times=T)\n",
    "f_model.addMeasure(measureName='ER',measureType='SV',lmax=13,units='nT/yr',data=ERav,rmsdata=None,times=T)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f145bc",
   "metadata": {},
   "source": [
    "Or load multiple models together like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70619e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "group_list=['BGS','CSES','DTU','GFZ','Huber','IPGP','ISTERRE','MISTA','NOAA','Strasbourg','TU_Berlin','UCM','USTHB','WHU']\n",
    "\n",
    "pygeodyn_results = 'PATH'\n",
    "\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'BGS_Current_computation.hdf5', 'BGS', 'green', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'CSES_Current_computation.hdf5', 'CSES', 'brown', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'DTU_Current_computation.hdf5', 'DTU', 'red', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'GFZ_Current_computation.hdf5', 'GFZ', 'orange', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'Huber_Current_computation.hdf5', 'HUBER', 'black', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'IPGP_Current_computation.hdf5', 'IPGP', 'yellow', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'ISTERRE_Current_computation.hdf5', 'ISTERRE', 'grey', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'Strasbourg_Current_computation.hdf5', 'ITES', 'cyan', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'MISTA_Current_computation.hdf5', 'MISTA', 'purple', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'NOAA_Current_computation.hdf5', 'NOAA', 'pink', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'TU_Berlin_Current_computation.hdf5', 'TUB', 'blue', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'UCM_Current_computation.hdf5', 'UCM', 'magenta', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'USTHB_Current_computation.hdf5', 'USTHB', 'deeppink', 'o','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'WHU_Current_computation.hdf5', 'WHU', 'teal', 'o','-')\n",
    "\n",
    "Model_list= list(PlotModels)\n",
    "\n",
    "Model_parameters=list(PlotModels['BGS'])\n",
    "Model_times=list(PlotModels['BGS']['Time'])\n",
    "\n",
    "print(\"List of Models = \" + str(Model_list))\n",
    "print(\"Parameters of Each Model = \" + str(Model_parameters))\n",
    "print(\"Model Time = \" + str(Model_times))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "847c5cad",
   "metadata": {},
   "source": [
    "Figure 2: Spectra of the SV, ER and U for 2020, 2025 and 2030 for all candidates "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a73680f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_SV, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, layout='constrained', figsize=(10,12.5))\n",
    "SV_spec = []\n",
    "ER_spec = []\n",
    "\n",
    "for i in range(len(Model_list)): \n",
    "    model = Model_list[i]\n",
    "    lmax = 13\n",
    "    x_SV = np.array(np.linspace(1,lmax, lmax))\n",
    "    loc = np.where(PlotModels[model]['Time'] == 2020.0)[0]\n",
    "    array2D_SV = PlotModels[model]['SV'][loc][0]\n",
    "    SV_spec = computeSVSpectra(lmax, array2D_SV)\n",
    "    array2D_ER = PlotModels[model]['ER'][loc][0]\n",
    "    ER_spec = computeSVSpectra(lmax, array2D_ER)\n",
    "    \n",
    "    ax1.plot(x_SV, np.array(SV_spec), label = model, color = PlotModels[model]['Color'], ls = '-', marker = PlotModels[model]['Marker'],  markersize=5, lw=1)\n",
    "    ax1.plot(x_SV, np.array(ER_spec), label = model, color = PlotModels[model]['Color'], ls = '--', marker = PlotModels[model]['Marker'],  markersize=5, lw=1)\n",
    "    ax1.set_title('SV and ER in January 2020', fontsize=14)\n",
    "    #ax1.set_xlabel('Spherical Harmonic Degree', fontsize=12)\n",
    "    ax1.set_ylabel('Spectral Energy $(nT/yr)^2$', fontsize=12)\n",
    "    #ax1.set_xticks(np.linspace(2,12, 6))\n",
    "    ax1.semilogy()\n",
    "    ax1.axis([0, lmax+1, 0.001, 10000])\n",
    "    ax1.set_box_aspect(1)\n",
    "    \n",
    "    lmax = 8\n",
    "    x_SV = np.array(np.linspace(1,lmax, lmax))\n",
    "    loc = np.where(PlotModels[model]['Time'] == 2025.0)[0]\n",
    "    array2D_SV = PlotModels[model]['SV'][loc][0]\n",
    "    SV_spec = computeSVSpectra(lmax, array2D_SV)\n",
    "    array2D_ER = PlotModels[model]['ER'][loc][0]\n",
    "    ER_spec = computeSVSpectra(lmax, array2D_ER)\n",
    "    \n",
    "    ax3.plot(x_SV, np.array(SV_spec), label = model, color = PlotModels[model]['Color'], ls = '-', marker = PlotModels[model]['Marker'],  markersize=5, lw=1)\n",
    "    ax3.plot(x_SV, np.array(ER_spec), label = model, color = PlotModels[model]['Color'], ls = '--', marker = PlotModels[model]['Marker'],  markersize=5, lw=1)\n",
    "    ax3.set_title('SV and ER in January 2025', fontsize=14)\n",
    "    #ax3.set_xlabel('Spherical Harmonic Degree', fontsize=12)\n",
    "    ax3.set_ylabel('Spectral Energy $(nT/yr)^2$', fontsize=12)\n",
    "    #ax3.set_xticks(np.linspace(2,12, 6))\n",
    "    ax3.semilogy()\n",
    "    ax3.axis([0, 14, 0.001, 10000])\n",
    "    ax3.set_box_aspect(1)\n",
    "    \n",
    "    loc = np.where(PlotModels[model]['Time'] == 2030.0)[0]\n",
    "    array2D_SV = PlotModels[model]['SV'][loc][0]\n",
    "    SV_spec = computeSVSpectra(lmax, array2D_SV)\n",
    "    array2D_ER = PlotModels[model]['ER'][loc][0]\n",
    "    ER_spec = computeSVSpectra(lmax, array2D_ER)\n",
    "    \n",
    "    ax5.plot(x_SV, np.array(SV_spec), label = model, color = PlotModels[model]['Color'], ls = '-', marker = PlotModels[model]['Marker'],  markersize=5, lw=1)\n",
    "    ax5.plot(x_SV, np.array(ER_spec), label = model, color = PlotModels[model]['Color'], ls = '--', marker = PlotModels[model]['Marker'],  markersize=5, lw=1)\n",
    "    ax5.set_title('SV and ER in January 2030', fontsize=14)\n",
    "    ax5.set_xlabel('Spherical Harmonic Degree', fontsize=12)\n",
    "    ax5.set_ylabel('Spectral Energy $(nT/yr)^2$', fontsize=12)\n",
    "    ax5.set_xticks(np.linspace(2,12, 6))\n",
    "    ax5.semilogy()\n",
    "    ax5.axis([0, 14, 0.001, 10000])\n",
    "    ax5.set_box_aspect(1)\n",
    "    \n",
    "handles,labels = ax1.get_legend_handles_labels()\n",
    "#ax1.legend( (handles[0], handles[2], handles[4], handles[6], handles[8], handles[10], Line2D([0], [0], color='tab:cyan'), Line2D([0], [0], color='tab:pink'),  Line2D([0], [0], color='green', ls= '--'), Line2D([0], [0], color='green', ls= 'dotted'), Line2D([0], [0], color='k'), Line2D([0], [0], ls='--', color='k'), Line2D([0], [0], ls='dotted', color='k')), ['Kalmag, 71p', 'Kalmag, 50p', 'Kalmag, 0p', 'Kalmag, Neutral_top1', 'Kalmag, Stable_top1', 'Kalmag, S1$^{\\gamma}$', 'CovObs.x2, Neutral_top1', 'CHAOS-7.16, Neutral_top1', 'Kalmag, $L_{SV}=13$', 'Kalmag, $L_{SV}=18$', 'SV', 'ER', 'Difference from SV model'], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax1.grid()\n",
    "ax3.grid()\n",
    "ax5.grid()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "lmax = 15\n",
    "x_U = np.array(np.linspace(1,lmax, lmax))\n",
    "#fig_U, (ax1) = plt.subplots(1, 1, layout='constrained', sharey=True, figsize=(7,5))\n",
    "U_spec = []\n",
    "\n",
    "for i in range(len(Model_list)): \n",
    "    model = Model_list[i]\n",
    "    loc = np.where(PlotModels[model]['Time'] == 2020.0)[0]\n",
    "    array2D_U = PlotModels[model]['U'][loc][0]\n",
    "    U_spec = computeUSpectra(lmax, array2D_U)\n",
    "    ax2.plot(x_U, np.array(U_spec), label = model, color = PlotModels[model]['Color'], ls = '-', marker = PlotModels[model]['Marker'],  markersize=5, lw=1)\n",
    "    ax2.set_title('U in January 2020', fontsize=14)\n",
    "    #ax2.set_xlabel('Spherical Harmonic Degree', fontsize=12)\n",
    "    ax2.set_ylabel('Spectral Energy $(km/yr)^2$', fontsize=12)\n",
    "    #ax2.set_xticks(np.linspace(2,16, 8))\n",
    "    ax2.semilogy()\n",
    "    ax2.axis([0, lmax+1, 0.1, 100])\n",
    "    ax2.set_box_aspect(1)\n",
    "    \n",
    "    loc = np.where(PlotModels[model]['Time'] == 2025.0)[0]\n",
    "    array2D_U = PlotModels[model]['U'][loc][0]\n",
    "    U_spec = computeUSpectra(lmax, array2D_U)\n",
    "    ax4.plot(x_U, np.array(U_spec), label = model, color = PlotModels[model]['Color'], ls = '-', marker = PlotModels[model]['Marker'],  markersize=5, lw=1)\n",
    "    ax4.set_title('U in January 2025', fontsize=14)\n",
    "    #ax4.set_xlabel('Spherical Harmonic Degree', fontsize=12)\n",
    "    ax4.set_ylabel('Spectral Energy $(km/yr)^2$', fontsize=12)\n",
    "    #ax4.set_xticks(np.linspace(2,16, 8))\n",
    "    ax4.semilogy()\n",
    "    ax4.axis([0, lmax+1, 0.1, 100])\n",
    "    ax4.set_box_aspect(1)\n",
    "    \n",
    "    loc = np.where(PlotModels[model]['Time'] == 2030.0)[0]\n",
    "    array2D_U = PlotModels[model]['U'][loc][0]\n",
    "    U_spec = computeUSpectra(lmax, array2D_U)\n",
    "    ax6.plot(x_U, np.array(U_spec), label = model, color = PlotModels[model]['Color'], ls = '-', marker = PlotModels[model]['Marker'],  markersize=5, lw=1)\n",
    "    ax6.set_title('U in January 2030', fontsize=14)\n",
    "    ax6.set_xlabel('Spherical Harmonic Degree', fontsize=12)\n",
    "    ax6.set_ylabel('Spectral Energy $(km/yr)^2$', fontsize=12)\n",
    "    ax6.set_xticks(np.linspace(2,16, 8))\n",
    "    ax6.semilogy()\n",
    "    ax6.axis([0, lmax+1, 0.1, 100])\n",
    "    ax6.set_box_aspect(1)\n",
    "    \n",
    "#ax1.legend( (handles[0], handles[2], handles[4], handles[6], handles[8], handles[10], Line2D([0], [0], color='tab:cyan'), Line2D([0], [0], color='tab:pink'),  Line2D([0], [0], color='green', ls= '--'), Line2D([0], [0], color='green', ls= 'dotted'), Line2D([0], [0], color='k'), Line2D([0], [0], ls='--', color='k'), Line2D([0], [0], ls='dotted', color='k')), ['Kalmag, 71p', 'Kalmag, 50p', 'Kalmag, 0p', 'Kalmag, Neutral_top1', 'Kalmag, Stable_top1', 'Kalmag, S1$^{\\gamma}$', 'CovObs.x2, Neutral_top1', 'CHAOS-7.16, Neutral_top1', 'Kalmag, $L_{SV}=13$', 'Kalmag, $L_{SV}=18$', 'SV', 'ER', 'Difference from SV model'], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax2.grid()\n",
    "ax4.grid()\n",
    "ax6.grid()\n",
    "\n",
    "handles,labels = ax2.get_legend_handles_labels()\n",
    "ax4.legend(handles, labels, bbox_to_anchor=(1,0.5), loc='center left', fontsize=10.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e24e2dbb",
   "metadata": {},
   "source": [
    "Figure 3: Flow in 2030 for the published Huber weighted mean model in space and the difference between each candidate and the published IGRF model. By altering the timestep, you can also plot the figures in the appendix. You may need to run the PlotModels cell above for this to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9195bc69",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_step= 2030.0\n",
    "loc = np.where(PlotModels['BGS']['Time'] == time_step)[0][0]\n",
    "Nph = 180\n",
    "Nth = 91\n",
    "x = np.linspace(-np.pi,np.pi,Nph)\n",
    "y = np.linspace(-np.pi/2+0.01,np.pi/2-0.01,Nth)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "myphi = x\n",
    "mytheta = np.pi/2-y\n",
    "phi1= x*180/np.pi\n",
    "lat = y*180/np.pi\n",
    "\n",
    "#####\n",
    "myfontsize=20\n",
    "vm=10\n",
    "dv=0.1\n",
    "Nlev = int((2*vm/dv)+1)\n",
    "levels = np.linspace(-vm,vm,Nlev)\n",
    "\n",
    "sum_diff_map = np.zeros((Nth, Nph))\n",
    "\n",
    "my_epoch = loc\n",
    "fig = plt.figure(figsize=(12,11))\n",
    "\n",
    "## REFERENCE HUBER\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "ref_model= readPlotmodelhdf5(str(pygeodyn_results)+'Huber_Current_computation.hdf5')\n",
    "measure = ref_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "ref_Uphi = griddata[\"ph\"]\n",
    "ref_Uth = griddata[\"th\"]\n",
    "ref_dated_Uphi = ref_Uphi[my_epoch,:,:]\n",
    "ref_dated_Uth =  (-1)*ref_Uth[my_epoch,:,:]\n",
    "U_abs = np.sqrt(ref_dated_Uphi**2+ ref_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_dated_Uphi**2+ ref_dated_Uth**2)))\n",
    "\n",
    "levels = np.linspace(-20,20,41)\n",
    "ax1 = fig.add_subplot(5,3,1,projection=ccrs.Mollweide())\n",
    "ax1_ref = ax1.contourf(phi1, lat, ref_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax1.coastlines(resolution='110m')\n",
    "ax1.streamplot(phi1, lat, ref_dated_Uphi, ref_dated_Uth,  transform=ccrs.PlateCarree(), density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax1.gridlines()\n",
    "ax1.set_title(r'HUBER in '+str(time_step))\n",
    "#plt.colorbar(ax_ref)#, ticks=np.linspace(-10, 10, 5))\n",
    "#plt.show()\n",
    "\n",
    "## BGS\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'BGS_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax2 = fig.add_subplot(5,3,2,projection=ccrs.Mollweide())\n",
    "ax2_ = ax2.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax2.coastlines(resolution='110m')\n",
    "ax2.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax2.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax2.set_title(r'BGS ('+str(np.round(corr,3))+')')\n",
    "#plt.colorbar(ax_)#, ticks=np.linspace(-10, 10, 5))\n",
    "#plt.show()\n",
    "\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "model1=U_abs\n",
    "model1_phi= my_dated_Uphi\n",
    "model1_th = my_dated_Uth\n",
    "\n",
    "## CSES\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'CSES_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax3 = fig.add_subplot(5,3,3,projection=ccrs.Mollweide())\n",
    "ax3_ = ax3.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax3.coastlines(resolution='110m')\n",
    "ax3.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(), density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax3.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax3.set_title(r'CSES ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model2=U_abs\n",
    "model2_phi= my_dated_Uphi\n",
    "model2_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)#, ticks=np.linspace(-10, 10, 5))\n",
    "#plt.show()\n",
    "\n",
    "## DTU\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'DTU_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax4 = fig.add_subplot(5,3,4,projection=ccrs.Mollweide())\n",
    "ax4_ = ax4.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax4.coastlines(resolution='110m')\n",
    "ax4.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(), density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax4.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax4.set_title(r'DTU ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model3=U_abs\n",
    "model3_phi= my_dated_Uphi\n",
    "model3_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)#, ticks=np.linspace(-10, 10, 5))\n",
    "#plt.show()\n",
    "\n",
    "## GFZ\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'GFZ_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax5 = fig.add_subplot(5,3,5,projection=ccrs.Mollweide())\n",
    "ax5_ = ax5.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax5.coastlines(resolution='110m')\n",
    "ax5.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax5.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax5.set_title(r'GFZ ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model4=U_abs\n",
    "model4_phi= my_dated_Uphi\n",
    "model4_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)#, ticks=np.linspace(-10, 10, 5))\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "\n",
    "## IPGP\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'IPGP_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax6 = fig.add_subplot(5,3,6,projection=ccrs.Mollweide())\n",
    "ax6_ = ax6.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax6.coastlines(resolution='110m')\n",
    "ax6.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax6.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax6.set_title(r'IPGP ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model5=U_abs\n",
    "model5_phi= my_dated_Uphi\n",
    "model5_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)#, ticks=np.linspace(-10, 10, 5))\n",
    "#plt.show()\n",
    "\n",
    "## ISTERRE\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'ISTERRE_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax7 = fig.add_subplot(5,3,7,projection=ccrs.Mollweide())\n",
    "ax7_ = ax7.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax7.coastlines(resolution='110m')\n",
    "ax7.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(), density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax7.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax7.set_title(r'ISTERRE ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model6=U_abs\n",
    "model6_phi= my_dated_Uphi\n",
    "model6_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)#, ticks=np.linspace(-10, 10, 5))\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "## MISTA\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'MISTA_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax9 = fig.add_subplot(5,3,9,projection=ccrs.Mollweide())\n",
    "ax9_ = ax9.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax9.coastlines(resolution='110m')\n",
    "ax9.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax9.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax9.set_title(r'MISTA ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model7=U_abs\n",
    "model7_phi= my_dated_Uphi\n",
    "model7_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)\n",
    "#plt.show()\n",
    "\n",
    "## NOAA\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'NOAA_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax10 = fig.add_subplot(5,3,10,projection=ccrs.Mollweide())\n",
    "ax10_ = ax10.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax10.coastlines(resolution='110m')\n",
    "ax10.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax10.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax10.set_title(r'NOAA ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model8=U_abs\n",
    "model8_phi= my_dated_Uphi\n",
    "model8_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)\n",
    "#plt.show()\n",
    "\n",
    "## Strasbourg\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'Strasbourg_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax8 = fig.add_subplot(5,3,8,projection=ccrs.Mollweide())\n",
    "ax8_ = ax8.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax8.coastlines(resolution='110m')\n",
    "ax8.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax8.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax8.set_title(r'ITES ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model9=U_abs\n",
    "model9_phi= my_dated_Uphi\n",
    "model9_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)\n",
    "#plt.show()\n",
    "\n",
    "## TU_Berlin\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'TU_Berlin_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax11 = fig.add_subplot(5,3,11,projection=ccrs.Mollweide())\n",
    "ax11.coastlines(resolution='110m')\n",
    "ax11.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax11.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax11.set_title(r'TUB ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model10=U_abs\n",
    "model10_phi= my_dated_Uphi\n",
    "model10_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)\n",
    "#plt.show()\n",
    "\n",
    "## UCM\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'UCM_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax12 = fig.add_subplot(5,3,12,projection=ccrs.Mollweide())\n",
    "ax12_ = ax12.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax12.coastlines(resolution='110m')\n",
    "ax12.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax12.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax12.set_title(r'UCM ('+str(np.round(corr,3))+')')\n",
    "\n",
    "\n",
    "model11=U_abs\n",
    "model11_phi= my_dated_Uphi\n",
    "model11_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)\n",
    "#plt.show()\n",
    "\n",
    "## USTHB\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'USTHB_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax13 = fig.add_subplot(5,3,13,projection=ccrs.Mollweide())\n",
    "ax13_ = ax13.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax13.coastlines(resolution='110m')\n",
    "ax13.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax13.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax13.set_title(r'USTHB ('+str(np.round(corr,3))+')')\n",
    "model12=U_abs\n",
    "model12_phi= my_dated_Uphi\n",
    "model12_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)\n",
    "#plt.show()\n",
    "\n",
    "## WHU\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'WHU_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:] - ref_dated_Uphi\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] - ref_dated_Uth\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_Uphi**2+ ref_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "levels = np.linspace(-5,5,21)\n",
    "ax14 = fig.add_subplot(5,3,14,projection=ccrs.Mollweide())\n",
    "ax14_ = ax14.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax14.coastlines(resolution='110m')\n",
    "ax14.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax14.gridlines()\n",
    "corr = np.corrcoef(my_Uphi[my_epoch,:,:].flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "ax14.set_title(r'WHU ('+str(np.round(corr,3))+')')\n",
    "\n",
    "model13=U_abs\n",
    "model13_phi= my_dated_Uphi\n",
    "model13_th = my_dated_Uth\n",
    "sum_diff_map = sum_diff_map+U_abs\n",
    "\n",
    "#plt.colorbar(ax_)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20660440",
   "metadata": {},
   "source": [
    "Figure 4: Spatial Huber weighed mean of deviation of flow inversion (see Fig 3). You will need to run the cell above for this to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f305f9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "maps = np.stack([model1, model2, model3, model4, model5, model6, model7,model8, model9, model10, model11, model12, model13])\n",
    "maps_phi = np.stack([model1_phi, model2_phi, model3_phi, model4_phi, model5_phi, model6_phi, model7_phi,model8_phi, model9_phi, model10_phi, model11_phi, model12_phi, model13_phi])\n",
    "maps_th = np.stack([model1_th, model2_th, model3_th, model4_th, model5_th, model6_th, model7_th,model8_th, model9_th, model10_th, model11_th, model12_th, model13_th])\n",
    "\n",
    "huber_mean_ph, huber_wts_ph = compute_huber_weighted_mean(maps_phi)\n",
    "huber_mean_th, huber_wts_th = compute_huber_weighted_mean(maps_th)\n",
    "huber_mean, huber_wts = compute_huber_weighted_mean(maps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26df43f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Broadcast mean to match maps shape\n",
    "mean_broadcast_ph = np.broadcast_to(huber_mean_ph, maps.shape)\n",
    "mean_broadcast_th = np.broadcast_to(huber_mean_th, maps.shape)\n",
    "mean_broadcast = np.broadcast_to(huber_mean, maps.shape)\n",
    "\n",
    "# Absolute deviation from the Huber mean\n",
    "abs_dev_ph = np.abs(maps - mean_broadcast_ph)  # shape: (num_models, H, W)\n",
    "abs_dev_th = np.abs(maps - mean_broadcast_th)  # shape: (num_models, H, W)\n",
    "abs_dev = np.abs(maps - mean_broadcast)  # shape: (num_models, H, W)\n",
    "\n",
    "# Weighted deviation\n",
    "weighted_dev_ph = abs_dev_ph * huber_wts_ph  # shape: (num_models, H, W)\n",
    "weighted_dev_th = abs_dev_th * huber_wts_th  # shape: (num_models, H, W)\n",
    "weighted_dev = abs_dev * huber_wts  # shape: (num_models, H, W)\n",
    "\n",
    "# --- Option 1: Mean deviation per pixel (across models) ---\n",
    "spatial_deviation_map_ph = np.nanmean(weighted_dev_ph, axis=0)  # shape: (H, W)\n",
    "spatial_deviation_map_th = np.nanmean(weighted_dev_th, axis=0)  # shape: (H, W)\n",
    "spatial_deviation_map = np.nanmean(weighted_dev, axis=0)  # shape: (H, W)\n",
    "\n",
    "# --- Option 2: Max deviation per pixel ---\n",
    "# spatial_deviation_map = np.nanmax(weighted_dev, axis=0)\n",
    "\n",
    "#plt.figure(figsize=(10, 5))\n",
    "#plt.imshow(spatial_deviation_map, cmap='Reds')\n",
    "#plt.colorbar(label='Mean Weighted Deviation')\n",
    "#plt.xlabel('Longitude Index')\n",
    "#plt.ylabel('Latitude Index')\n",
    "#plt.tight_layout()\n",
    "#plt.show()\n",
    "\n",
    "print(r'Minimum $U_\\phi$ huber weighted deviation:'+str(np.min(spatial_deviation_map_ph))+r', Maximum $U_\\phi$ huber weighted deviation:'+str(np.max(spatial_deviation_map_ph)))\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "levels = np.linspace(0,2.4,49)\n",
    "ax1 = fig.add_subplot(1,1,1,projection=ccrs.Mollweide())\n",
    "ax1_ = ax1.contourf(phi1, lat, spatial_deviation_map_ph, levels, transform=ccrs.PlateCarree(),cmap='Reds',extend='both')\n",
    "ax1.coastlines(resolution='110m')\n",
    "ax1.gridlines()\n",
    "plt.title(r'Spatial map of weighted $U_\\phi$ flow speed deviations from Huber mean')\n",
    "plt.colorbar(ax1_, label=r'Flow speed deviation (km/yr)', cmap='RdBu_r', location = 'bottom')\n",
    "plt.show()\n",
    "\n",
    "print(r'Minimum $U_\\theta$ huber weighted deviation:'+str(np.min(spatial_deviation_map_th))+r', Maximum $U_\\theta$ huber weighted deviation:'+str(np.max(spatial_deviation_map_th)))\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "levels = np.linspace(0,2.4,49)\n",
    "ax1 = fig.add_subplot(1,1,1,projection=ccrs.Mollweide())\n",
    "ax1_ = ax1.contourf(phi1, lat, spatial_deviation_map_th,levels, transform=ccrs.PlateCarree(),cmap='Reds')\n",
    "ax1.coastlines(resolution='110m')\n",
    "ax1.gridlines()\n",
    "plt.title(r'Spatial map of weighted $U_\\theta$ flow speed deviations from Huber mean')\n",
    "plt.colorbar(ax1_, label=r'Flow speed deviation (km/yr)', cmap='RdBu_r', location = 'bottom')\n",
    "plt.show()\n",
    "\n",
    "print(r'Minimum $U$ huber weighted deviation:'+str(np.min(spatial_deviation_map))+', Maximum $U$ huber weighted deviation:'+str(np.max(spatial_deviation_map)))\n",
    "fig = plt.figure(figsize=(8,5))\n",
    "levels = np.linspace(0,2.4,49)\n",
    "ax1 = fig.add_subplot(1,1,1,projection=ccrs.Mollweide())\n",
    "ax1_ = ax1.contourf(phi1, lat, spatial_deviation_map, levels, transform=ccrs.PlateCarree(),cmap='Reds',extend='both')\n",
    "ax1.coastlines(resolution='110m')\n",
    "ax1.gridlines()\n",
    "plt.title(r'Spatial map of weighted absolute flow speed deviations from Huber mean')\n",
    "plt.colorbar(ax1_, label=r'Flow speed deviation (km/yr)', cmap='RdBu_r', location = 'bottom')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72d3022d",
   "metadata": {},
   "source": [
    "Figure 5: Time-longitude plot of Uphi at the equator over the 10 year period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c3d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TL_start = 2020.0\n",
    "TL_end = 2030.0\n",
    "loc_start = np.where(PlotModels['BGS']['Time'] == TL_start)[0][0]\n",
    "loc_end = np.where(PlotModels['BGS']['Time'] == TL_end)[0][0]\n",
    "color_speed = 20\n",
    "lat_request = 91\n",
    "Nph = 360\n",
    "Nth = 181\n",
    "x = np.linspace(0,2*np.pi,Nph)\n",
    "y = np.linspace(-np.pi/2+0.01,np.pi/2-0.01,Nth)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "myphi = x\n",
    "mytheta = np.pi/2-y\n",
    "phi1= x*180/np.pi\n",
    "lat = y*180/np.pi\n",
    "cmap= 'RdBu_r'\n",
    "\n",
    "#####\n",
    "myfontsize=20\n",
    "vm=20\n",
    "dv=0.1\n",
    "\n",
    "fig_TL, ((ax1, ax2, ax3), (ax4, ax5, ax6), (ax7, ax8, ax9), (ax10, ax11, ax12), (ax13, ax14, ax15)) = plt.subplots(5, 3, layout='constrained', sharex=True,sharey=True, figsize=(8,8))\n",
    "#fig1, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, layout='constrained', figsize=(8,8), sharex= True, sharey = True)\n",
    "\n",
    "ref_model= readPlotmodelhdf5(str(pygeodyn_results)+'Huber_Current_computation.hdf5')\n",
    "measure = ref_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "ref_Uphi = griddata[\"ph\"]\n",
    "\n",
    "ref_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    ref_eq_Uphi[:,i] = ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax1.imshow(np.flipud(ref_eq_Uphi), cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "ax1.set_title(r'Huber')\n",
    "\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'BGS_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i] #- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax2.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "\n",
    "epoch1 = 4\n",
    "epoch2 = 9\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax2.set_title(r'BGS ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "#fig_TL, (ax1) = plt.subplots(1, 1, layout='constrained', sharey=True, figsize=(7,5))\n",
    "#fig1, ((ax1, ax2), (ax3, ax4), (ax5, ax6), (ax7, ax8)) = plt.subplots(4, 2, layout='constrained', figsize=(8,8), sharex= True, sharey = True)\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'CSES_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax3.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax3.set_title(r'CSES ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'DTU_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax4.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax4.set_title(r'DTU ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'GFZ_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax5.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax5.set_title(r'GFZ ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'IPGP_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax6.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax6.set_title(r'IPGP ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'ISTERRE_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax7.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax7.set_title(r'ISTERRE ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'MISTA_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax9.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax9.set_title(r'MISTA ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'NOAA_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax10.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax10.set_title(r'NOAA ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'Strasbourg_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax8.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax8.set_title(r'ITES ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'TU_Berlin_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax11.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax11.set_title(r'TUB ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'UCM_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax12.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax12.set_title(r'UCM ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'USTHB_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax13.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax13.set_title(r'USTHB ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'WHU_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "\n",
    "my_eq_Uphi = np.zeros((loc_end-loc_start, Nph))\n",
    "for i in range(Nph):\n",
    "    my_eq_Uphi[:,i] = my_Uphi[loc_start:loc_end,lat_request,i]#- ref_Uphi[loc_start:loc_end,lat_request,i]\n",
    "ax14.imshow(np.flipud(my_eq_Uphi),cmap=cmap, extent=[0, 360, TL_start, TL_end], aspect='auto', vmin=-color_speed, vmax=color_speed)\n",
    "corr2023 = np.corrcoef(my_eq_Uphi[epoch1,:].flatten(), ref_eq_Uphi[epoch1,:].flatten())[0,1]\n",
    "corr2028 = np.corrcoef(my_eq_Uphi[epoch2:].flatten(), ref_eq_Uphi[epoch2,:].flatten())[0,1]\n",
    "ax14.set_title(r'WHU ('+str(np.round(corr2023,3))+', '+str(np.round(corr2028,3))+')')\n",
    "\n",
    "ax1.set_yticks([2020, 2025, 2030])\n",
    "ax4.set_yticks([2020, 2025, 2030])\n",
    "ax7.set_yticks([2020, 2025, 2030])\n",
    "ax10.set_yticks([2020, 2025, 2030])\n",
    "ax13.set_yticks([2020, 2025, 2030])\n",
    "\n",
    "ax1.set_ylabel(r'Time (Year)')\n",
    "ax4.set_ylabel(r'Time (Year)')\n",
    "ax7.set_ylabel(r'Time (Year)')\n",
    "ax10.set_ylabel(r'Time (Year)')\n",
    "ax13.set_ylabel(r'Time (Year)')\n",
    "\n",
    "ax13.set_xlabel(r'Longitude (Degrees)')\n",
    "ax14.set_xlabel(r'Longitude (Degrees)')\n",
    "ax12.set_xlabel(r'Longitude (Degrees)')\n",
    "\n",
    "ax13.set_xticks([0, 90, 180, 270, 360])\n",
    "ax14.set_xticks([0, 90, 180, 270, 360])\n",
    "ax12.set_xticks([0, 90, 180, 270, 360])\n",
    "\n",
    "\n",
    "ax1.grid()\n",
    "ax2.grid()\n",
    "ax3.grid()\n",
    "ax4.grid()\n",
    "ax5.grid()\n",
    "ax6.grid()\n",
    "ax7.grid()\n",
    "ax8.grid()\n",
    "ax9.grid()\n",
    "ax10.grid()\n",
    "ax11.grid()\n",
    "ax12.grid()\n",
    "ax13.grid()\n",
    "ax14.grid()\n",
    "\n",
    "cax = axes[14]\n",
    "cax.axis('off')  # turn off map projection\n",
    "# Create a colorbar axis inside it\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "cbar_ax = inset_axes(cax, width=\"40%\", height=\"80%\", loc='center')\n",
    "\n",
    "# --- Create the shared colorbar ---\n",
    "norm = mcolors.Normalize(vmin=-color_speed, vmax=color_speed)\n",
    "sm = cm.ScalarMappable(cmap=cmap, norm=norm)\n",
    "sm.set_array([])\n",
    "\n",
    "fig.colorbar(sm, cax=cbar_ax, orientation='vertical', label='Zonal wind speed (m/s)')\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d06992",
   "metadata": {},
   "source": [
    "Figure 6(a) Plots of flow for DTU and Kalmag for Lsv=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865a21b8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "time_step= 2030.0\n",
    "loc = np.where(PlotModels['BGS']['Time'] == time_step)[0][0]\n",
    "Nph = 180\n",
    "Nth = 91\n",
    "x = np.linspace(-np.pi,np.pi,Nph)\n",
    "y = np.linspace(-np.pi/2+0.01,np.pi/2-0.01,Nth)\n",
    "X,Y = np.meshgrid(x,y)\n",
    "myphi = x\n",
    "mytheta = np.pi/2-y\n",
    "phi1= x*180/np.pi\n",
    "lat = y*180/np.pi\n",
    "\n",
    "#####\n",
    "myfontsize=20\n",
    "vm=20\n",
    "dv=0.1\n",
    "Nlev = int((2*vm/dv)+1)\n",
    "levels = np.linspace(-vm,vm,Nlev)\n",
    "\n",
    "sum_diff_map = np.zeros((Nth, Nph))\n",
    "\n",
    "my_epoch = loc\n",
    "fig = plt.figure(figsize=(12,11))\n",
    "\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "ref_model= readPlotmodelhdf5(str(pygeodyn_results)+'Huber_Current_computation.hdf5')\n",
    "measure = ref_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "ref_Uphi = griddata[\"ph\"]\n",
    "ref_Uth = griddata[\"th\"]\n",
    "ref_dated_Uphi = ref_Uphi[my_epoch,:,:]\n",
    "ref_dated_Uth =  (-1)*ref_Uth[my_epoch,:,:]\n",
    "\n",
    "## DTU L=8\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'DTU_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:]\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:]\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_dated_Uphi**2+ ref_dated_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "ax1 = fig.add_subplot(3,2,1, projection=ccrs.Mollweide())\n",
    "ax1_ = ax1.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax1.coastlines(resolution='110m')\n",
    "ax1.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(), density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax1.gridlines()\n",
    "ax1.set_title(r'DTU L=8 2030')\n",
    "\n",
    "modeldtu8=U_abs\n",
    "modeldtu8_phi= my_dated_Uphi\n",
    "modeldtu8_th = my_dated_Uth\n",
    "\n",
    "## TU_Berlin\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'TU_Berlin_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:]\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:] \n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_dated_Uphi**2+ ref_dated_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "ax2 = fig.add_subplot(3,2,2,projection=ccrs.Mollweide())\n",
    "ax2.coastlines(resolution='110m')\n",
    "ax2.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax2.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax2.gridlines()\n",
    "ax2.set_title(r'TUB L=8 2030')\n",
    "\n",
    "modeltub8=U_abs\n",
    "modeltub8_phi= my_dated_Uphi\n",
    "modeltub8_th = my_dated_Uth\n",
    "\n",
    "## DTU L=13\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'DTU_13_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:]\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:]\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_dated_Uphi**2+ ref_dated_Uth**2)))\n",
    "\n",
    "#fig=plt.figure(figsize=(6,3))\n",
    "ax3 = fig.add_subplot(3,2,3,projection=ccrs.Mollweide())\n",
    "ax3_ = ax3.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax3.coastlines(resolution='110m')\n",
    "ax3.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(), density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax3.gridlines()\n",
    "ax3.set_title(r'DTU L=13 2030')\n",
    "\n",
    "modeldtu13=U_abs\n",
    "modeldtu13_phi= my_dated_Uphi\n",
    "modeldtu13_th = my_dated_Uth\n",
    "lw = 5*(modeldtu13-modeldtu8)  / (0.5*np.max(np.sqrt(ref_dated_Uphi**2+ ref_dated_Uth**2)))\n",
    "\n",
    "ax5 = fig.add_subplot(3,2,5,projection=ccrs.Mollweide())\n",
    "ax5_ = ax5.contourf(phi1, lat, modeldtu13_phi-modeldtu8_phi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax5.coastlines(resolution='110m')\n",
    "ax5.streamplot(phi1, lat, modeldtu13_phi-modeldtu8_phi, modeldtu13_th-modeldtu8_th,  transform=ccrs.PlateCarree(), density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax5.gridlines()\n",
    "ax5.set_title(r'DTU 2030 L=13 map - L=8 map')\n",
    "\n",
    "\n",
    "## TU_Berlin\n",
    "PlotModels1 = webgeodyn.models.Models()\n",
    "my_model= readPlotmodelhdf5(str(pygeodyn_results)+'TU_Berlin_13_Current_computation.hdf5')\n",
    "measure = my_model.measures['U']\n",
    "components=[\"th\",\"ph\"]\n",
    "griddata = measure.computeRThetaPhiData(rC, mytheta, myphi,components=components,computeallrealisation=False,irealisation=-1)\n",
    "my_Uphi = griddata[\"ph\"]\n",
    "my_Uth = griddata[\"th\"]\n",
    "my_dated_Uphi = my_Uphi[my_epoch,:,:]\n",
    "my_dated_Uth =  (-1)*my_Uth[my_epoch,:,:]\n",
    "U_abs = np.sqrt(my_dated_Uphi**2+ my_dated_Uth**2)\n",
    "PHI, THETA = np.mgrid[-180:180:180j, -90:90:91j]\n",
    "lw = 5*U_abs / (0.5*np.max(np.sqrt(ref_dated_Uphi**2+ ref_dated_Uth**2)))\n",
    "\n",
    "ax4 = fig.add_subplot(3,2,4, projection=ccrs.Mollweide())\n",
    "ax4.coastlines(resolution='110m')\n",
    "ax4.contourf(phi1, lat, my_dated_Uphi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax4.streamplot(phi1, lat, my_dated_Uphi, my_dated_Uth,  transform=ccrs.PlateCarree(),  density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax4.gridlines()\n",
    "ax4.set_title(r'TUB L=13 2030')\n",
    "\n",
    "modeltub13=U_abs\n",
    "modeltub13_phi= my_dated_Uphi\n",
    "modeltub13_th = my_dated_Uth\n",
    "\n",
    "lw = 5*(modeltub13-modeltub8)  / (0.5*np.max(np.sqrt(ref_dated_Uphi**2+ ref_dated_Uth**2)))\n",
    "\n",
    "ax6 = fig.add_subplot(3,2,6,projection=ccrs.Mollweide())\n",
    "ax6_ = ax6.contourf(phi1, lat, modeltub13_phi-modeltub8_phi, levels, transform=ccrs.PlateCarree(),cmap='RdBu_r',extend='both')\n",
    "ax6.coastlines(resolution='110m')\n",
    "ax6.streamplot(phi1, lat, modeltub13_phi-modeltub8_phi, modeltub13_th-modeltub8_th,  transform=ccrs.PlateCarree(), density=[1.5, 0.75], color='k', linewidth = lw)\n",
    "ax6.gridlines()\n",
    "ax6.set_title(r'TUB 2030 L=13 map - L=8 map')\n",
    "\n",
    "\n",
    "#plt.colorbar(ax_)\n",
    "#plt.show()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fede6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlations for the L=13 maps against the Huber L=8 reference\n",
    "corr = np.corrcoef(modeldtu13_phi.flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "print(corr)\n",
    "\n",
    "corr = np.corrcoef(modeltub13_phi.flatten(), ref_Uphi[my_epoch,:,:].flatten())[0,1]\n",
    "print(corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d50020f",
   "metadata": {},
   "source": [
    "Figure 6(b) Spectra of the SV and U for the DTU and Kalmag for Lsv=13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78233afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'DTU_13_Current_computation.hdf5', 'DTU_13', 'red', 'x','-')\n",
    "PlotModels = readmodelhdf5(str(pygeodyn_results)+'TU_Berlin_13_Current_computation.hdf5', 'TUB_13', 'blue', 'x','-')\n",
    "\n",
    "\n",
    "fig_SV, ((ax1), (ax2)) = plt.subplots(2, 1, layout='constrained', figsize=(8,8))\n",
    "SV_spec = []\n",
    "ER_spec = []\n",
    "\n",
    "loc = np.where(PlotModels['DTU']['Time'] == 2030.0)[0]\n",
    "lmax = 8\n",
    "x_SV = np.array(np.linspace(1,lmax, lmax))\n",
    "array2D_SV = PlotModels['DTU']['SV'][loc][0]\n",
    "DTU_spec = computeSVSpectra(lmax, array2D_SV)\n",
    "array2D_ER = PlotModels['DTU']['ER'][loc][0]\n",
    "DTU_ERspec = computeSVSpectra(lmax, array2D_ER)\n",
    "ax1.plot(x_SV, np.array(DTU_spec), label = 'DTU, L=8', color = PlotModels['DTU']['Color'], ls = '-', marker = PlotModels['DTU']['Marker'],  markersize=5, lw=1)\n",
    "ax1.plot(x_SV, np.array(DTU_ERspec), label = 'DTU, L=8', color = PlotModels['DTU']['Color'], ls = '--', marker = PlotModels['DTU']['Marker'],  markersize=5, lw=1)\n",
    "\n",
    "array2D_SV = PlotModels['TUB']['SV'][loc][0]\n",
    "TUB_spec = computeSVSpectra(lmax, array2D_SV)\n",
    "array2D_ER = PlotModels['TUB']['ER'][loc][0]\n",
    "TUB_ERspec = computeSVSpectra(lmax, array2D_ER)\n",
    "ax1.plot(x_SV, np.array(TUB_spec), label = 'TUB, L=8', color = PlotModels['TUB']['Color'], ls = '-', marker = PlotModels['TUB']['Marker'],  markersize=5, lw=1)\n",
    "ax1.plot(x_SV, np.array(TUB_ERspec), label = 'TUB, L=8', color = PlotModels['TUB']['Color'], ls = '--', marker = PlotModels['TUB']['Marker'],  markersize=5, lw=1)\n",
    "\n",
    "lmax = 13\n",
    "x_SV = np.array(np.linspace(1,lmax, lmax))\n",
    "array2D_SV = PlotModels['DTU_13']['SV'][loc][0]\n",
    "DTU13_spec = computeSVSpectra(lmax, array2D_SV)\n",
    "array2D_ER = PlotModels['DTU_13']['ER'][loc][0]\n",
    "DTU13_ERspec = computeSVSpectra(lmax, array2D_ER)\n",
    "ax1.plot(x_SV, np.array(DTU13_spec), label = 'DTU, L=13', color = PlotModels['DTU_13']['Color'], ls = '-', marker = PlotModels['DTU_13']['Marker'],  markersize=5, lw=1)\n",
    "ax1.plot(x_SV, np.array(DTU13_ERspec), label = 'DTU, L=13', color = PlotModels['DTU_13']['Color'], ls = '--', marker = PlotModels['DTU_13']['Marker'],  markersize=5, lw=1)\n",
    "\n",
    "array2D_SV = PlotModels['TUB_13']['SV'][loc][0]\n",
    "TUB13_spec = computeSVSpectra(lmax, array2D_SV)\n",
    "array2D_ER = PlotModels['TUB_13']['ER'][loc][0]\n",
    "TUB13_ERspec = computeSVSpectra(lmax, array2D_ER)\n",
    "ax1.plot(x_SV, np.array(TUB13_spec), label = 'TUB, L=13', color = PlotModels['TUB_13']['Color'], ls = '-', marker = PlotModels['TUB_13']['Marker'],  markersize=5, lw=1)\n",
    "ax1.plot(x_SV, np.array(TUB13_ERspec), label = 'TUB, L=13', color = PlotModels['TUB_13']['Color'], ls = '--', marker = PlotModels['TUB_13']['Marker'],  markersize=5, lw=1)\n",
    "\n",
    "#lmax = 8\n",
    "#x_SV = np.array(np.linspace(1,lmax, lmax))\n",
    "#ax1.plot(x_SV, np.array(DTU_spec-DTU13_spec[:lmax]), label = 'DTU difference', color = PlotModels['DTU']['Color'], ls = ':', marker = PlotModels['DTU_13']['Marker'],  markersize=5, lw=1)\n",
    "#ax1.plot(x_SV, np.array(TUB_spec-TUB13_spec[:lmax]), label = 'TU_Berlin difference', color = PlotModels['TU_Berlin']['Color'], ls = ':', marker = PlotModels['TU_Berlin_13']['Marker'],  markersize=5, lw=1)\n",
    "#lmax = 13\n",
    "\n",
    "ax1.set_title('SV and ER in January 2030', fontsize=14)\n",
    "ax1.set_xlabel('Spherical Harmonic Degree', fontsize=12)\n",
    "ax1.set_ylabel('Spectral Energy $(nT/yr)^2$', fontsize=12)\n",
    "#ax1.set_xticks(np.linspace(2,12, 6))\n",
    "ax1.semilogy()\n",
    "ax1.axis([0, lmax+1, 0.01, 10000])\n",
    "ax1.set_box_aspect(1)\n",
    "    \n",
    "handles,labels = ax1.get_legend_handles_labels()\n",
    "#ax1.legend( (handles[0], handles[2], handles[4], handles[6], handles[8], handles[10], Line2D([0], [0], color='tab:cyan'), Line2D([0], [0], color='tab:pink'),  Line2D([0], [0], color='green', ls= '--'), Line2D([0], [0], color='green', ls= 'dotted'), Line2D([0], [0], color='k'), Line2D([0], [0], ls='--', color='k'), Line2D([0], [0], ls='dotted', color='k')), ['Kalmag, 71p', 'Kalmag, 50p', 'Kalmag, 0p', 'Kalmag, Neutral_top1', 'Kalmag, Stable_top1', 'Kalmag, S1$^{\\gamma}$', 'CovObs.x2, Neutral_top1', 'CHAOS-7.16, Neutral_top1', 'Kalmag, $L_{SV}=13$', 'Kalmag, $L_{SV}=18$', 'SV', 'ER', 'Difference from SV model'], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax1.grid()\n",
    "#plt.show()\n",
    "\n",
    "\n",
    "lmax = 15\n",
    "x_U = np.array(np.linspace(1,lmax, lmax))\n",
    "#fig_U, (ax1) = plt.subplots(1, 1, layout='constrained', sharey=True, figsize=(7,5))\n",
    "U_spec = []\n",
    "\n",
    "x_SV = np.array(np.linspace(1,lmax, lmax))\n",
    "array2D_U = PlotModels['DTU']['U'][loc][0]\n",
    "DTU_spec = computeSVSpectra(lmax, array2D_U)\n",
    "ax2.plot(x_U, np.array(DTU_spec), label = 'DTU, L=8', color = PlotModels['DTU']['Color'], ls = '-', marker = PlotModels['DTU']['Marker'],  markersize=5, lw=1)\n",
    "\n",
    "array2D_U = PlotModels['TUB']['U'][loc][0]\n",
    "TUB_spec = computeSVSpectra(lmax, array2D_U)\n",
    "ax2.plot(x_U, np.array(TUB_spec), label = 'TUB, L=8', color = PlotModels['TUB']['Color'], ls = '-', marker = PlotModels['TUB']['Marker'],  markersize=5, lw=1)\n",
    "\n",
    "array2D_U = PlotModels['ITES']['U'][loc][0]\n",
    "ITES_spec = computeSVSpectra(lmax, array2D_U)\n",
    "ax2.plot(x_U, np.array(ITES_spec), label = 'ITES, L=8', color = PlotModels['ITES']['Color'], ls = '-', marker = PlotModels['ITES']['Marker'],  markersize=5, lw=1)\n",
    "\n",
    "array2D_U = PlotModels['DTU_13']['U'][loc][0]\n",
    "DTU13_spec = computeSVSpectra(lmax, array2D_U)\n",
    "ax2.plot(x_U, np.array(DTU13_spec), label = 'DTU, L=13', color = PlotModels['DTU']['Color'], ls = '-', marker = PlotModels['DTU_13']['Marker'],  markersize=5, lw=1)\n",
    "\n",
    "array2D_U = PlotModels['TUB_13']['U'][loc][0]\n",
    "TUB13_spec = computeSVSpectra(lmax, array2D_U)\n",
    "ax2.plot(x_U, np.array(TUB13_spec), label = 'TUB, L=13', color = PlotModels['TUB']['Color'], ls = '-', marker = PlotModels['TUB_13']['Marker'],  markersize=5, lw=1)\n",
    "\n",
    "ax2.set_title('U in January 2030', fontsize=14)\n",
    "ax2.set_xlabel('Spherical Harmonic Degree', fontsize=12)\n",
    "ax2.set_ylabel('Spectral Energy $(km/yr)^2$', fontsize=12)\n",
    "ax2.set_xticks(np.linspace(0,14, 8))\n",
    "ax2.semilogy()\n",
    "ax2.axis([0, lmax+1, 0.5, 200])\n",
    "ax2.set_box_aspect(1)\n",
    "    \n",
    "#ax1.legend( (handles[0], handles[2], handles[4], handles[6], handles[8], handles[10], Line2D([0], [0], color='tab:cyan'), Line2D([0], [0], color='tab:pink'),  Line2D([0], [0], color='green', ls= '--'), Line2D([0], [0], color='green', ls= 'dotted'), Line2D([0], [0], color='k'), Line2D([0], [0], ls='--', color='k'), Line2D([0], [0], ls='dotted', color='k')), ['Kalmag, 71p', 'Kalmag, 50p', 'Kalmag, 0p', 'Kalmag, Neutral_top1', 'Kalmag, Stable_top1', 'Kalmag, S1$^{\\gamma}$', 'CovObs.x2, Neutral_top1', 'CHAOS-7.16, Neutral_top1', 'Kalmag, $L_{SV}=13$', 'Kalmag, $L_{SV}=18$', 'SV', 'ER', 'Difference from SV model'], loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "ax2.grid()\n",
    "#ax2.grid()\n",
    "\n",
    "handles,labels = ax2.get_legend_handles_labels()\n",
    "ax2.legend(handles, labels, loc = 'best')#bbox_to_anchor=(1,0.5), loc='center left', fontsize=10.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef52ef03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6816fee2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
